{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["_8sO3m-18yR2","iviZ5qlK82VV","XD6Ncms2oz6V","2SN2CDoiTx9t","HDqMqwAro4Hs","CXetnDKVNzxC","Nsg78lD-eUak","h09MJoiYeUa7","l9SLdML4duXo","YVZkGJk8tLaC","U7_x1y5JB6sJ","aNTXV2gRUCDy","uoRGYqk_o_D3","vePZz3ftCL7W","75iGjfcKCOvf","KoZY3PmVCL7Y","hT5K1VmXS04o","yceouMyjVb1q","yWBIFLMiCL7Z"],"authorship_tag":"ABX9TyNj8KDGO0aBYO9VB5kmVamq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Libraries"],"metadata":{"id":"_8sO3m-18yR2"}},{"cell_type":"code","source":["!pip install shap\n","!pip install scikeras\n","!pip install aif360\n","!pip install fairlearn"],"metadata":{"id":"MskFK84ixs1X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install aif360[inFairness]\n","!pip install aif360[OptimalTransport]"],"metadata":{"id":"pztQ6UFskuNv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import Callback\n","from tensorflow import keras\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","import matplotlib.pyplot as plt\n","import copy"],"metadata":{"id":"fa969uVksoA4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loading Data"],"metadata":{"id":"iviZ5qlK82VV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0caD0PNEc_ZV"},"outputs":[],"source":["# Load the dataset\n","url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n","column_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n","data = pd.read_csv(url, header=None, names=column_names)\n","outcomes = data['Outcome']\n","data_columns = list(data.columns)"]},{"cell_type":"code","source":["scaler = StandardScaler()\n","data_scaled = pd.DataFrame(scaler.fit_transform(data))\n","# data_scaled = data_scaled.drop(columns=[8])"],"metadata":{"id":"q3aISfnwo7gl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_pd = pd.concat([data_scaled, outcomes], axis=1)\n","data_pd = data_pd.rename(columns={0:data_columns[0], 1:data_columns[1], 2:data_columns[2],\n","                                  3:data_columns[3], 4:data_columns[4], 5:data_columns[5],\n","                                  6:data_columns[6], 7:data_columns[7]})\n","data_pd"],"metadata":{"id":"r21Bkj-CeaDC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["min_age = data_pd['Age'].min()\n","max_age = data_pd['Age'].max()\n","avg_age = data_pd['Age'].mean()\n","min_age, max_age, avg_age"],"metadata":{"id":"B89SbxcxBJxK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Statistical Analysis"],"metadata":{"id":"XD6Ncms2oz6V"}},{"cell_type":"markdown","source":["In this section, we thoroughly analyze the values for different features to extract feature-related rules and constraints as well as examining their lower/upper bounds"],"metadata":{"id":"8_NJB2OU9YF1"}},{"cell_type":"code","source":["data_positive = data_pd[data_pd['Outcome']==1]\n","data_negative = data_pd[data_pd['Outcome']==0]"],"metadata":{"id":"LH7Osh6WekOU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_positive.columns"],"metadata":{"id":"yxiTPFZ9Uo9d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## To check the probabilities for different features, please modify the 'key' variable below,\n","## as well as the lower and upper bounds for 'pos_freq' and 'neg_freq' variables.\n","\n","# key = 'Glucose'\n","# key = 'BloodPressure'\n","# key = 'SkinThickness'\n","# key = 'Insulin'\n","# key = 'BMI'\n","# key = 'DiabetesPedigreeFunction'\n","# key = 'Age'\n","key = 'Pregnancies'\n","\n","# pos_freq = len(data_positive[key][(data_positive[key]<200) & (data_positive[key]>170)])\n","# neg_freq = len(data_negative[key][(data_negative[key]<200) & (data_negative[key]>170)])\n","\n","pos_freq = len(data_positive[key][(data_positive[key]<40) & (data_positive[key]>20)])\n","neg_freq = len(data_negative[key][(data_negative[key]<40) & (data_negative[key]>20)])\n","\n","print('Frequency:', pos_freq, neg_freq)\n","print('Max:',np.max(data_positive[key]), np.max(data_negative[key]))\n","(pos_freq+1)/(neg_freq+pos_freq+1), (neg_freq+1)/(pos_freq+neg_freq+1)"],"metadata":{"id":"Kssdlh4DcPAx"},"execution_count":null,"outputs":[]},{"source":["## We can illustrate the positive or negative plots either individually or together.\n","## Plotting such figures can assisst us in determing the rules and lower/upper bounds of the values\n","## as well as identifying within which range of values the probability of positive/negative labels is higher\n","## Using such insights, we step by step define and examine the statistical analysis-based constraints\n","\n","from matplotlib import pyplot as plt\n","\n","# data_negative[key].plot(label='-')\n","# data_positive[key].plot(label='+')\n","\n","data_negative[key].plot(kind='hist', bins=20, label='-')\n","data_positive[key].plot(kind='hist', bins=20, label='+')\n","plt.legend()\n","plt.gca().spines[['top', 'right',]].set_visible(False)"],"cell_type":"code","execution_count":null,"outputs":[],"metadata":{"id":"yTxB73vFUmOD"}},{"cell_type":"markdown","source":["### Dataset Prepation"],"metadata":{"id":"2SN2CDoiTx9t"}},{"cell_type":"code","source":["# Split data into features and target variable\n","data_pd = data_pd.drop(8, axis=1)\n","X = data_pd.drop('Outcome', axis=1)\n","y = data_pd['Outcome']"],"metadata":{"id":"-NVbct6uVepy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","print(X_train.shape, y_train.shape)\n","print(X_test.shape, y_test.shape)"],"metadata":{"id":"KAjsIM35eYOD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 16\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)))\n","train_dataset = train_dataset.batch(batch_size)\n","\n","test_dataset = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(X_test), tf.convert_to_tensor(y_test)))\n","test_dataset = test_dataset.batch(batch_size)"],"metadata":{"id":"rjkn4v45NqFt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Trivial Learning"],"metadata":{"id":"HDqMqwAro4Hs"}},{"cell_type":"code","source":["# Define the CNN model\n","original_model = Sequential([\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(64, activation='relu'),\n","    Dense(32, activation='relu'),\n","    Dropout(0.5),\n","    Dense(2, activation='softmax')\n","])\n","\n","## EarlyStopping\n","best_loss = float('inf')\n","best_model_weights = None\n","patience = 20\n","val_loss_metric = keras.losses.SparseCategoricalCrossentropy()\n","early_stopping = True\n","###\n","\n","loss_fn = keras.losses.SparseCategoricalCrossentropy()\n","optimizer = Adam()\n","n_epochs = 100\n","\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","for epoch in range(n_epochs):\n","  print(\"\\nEpoch %d\" % (epoch,))\n","  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","    with tf.GradientTape() as tape:\n","        logits = original_model(x_batch_train, training=True)  # Logits for this minibatch\n","        loss_value = loss_fn(y_batch_train, logits)\n","\n","    grads = tape.gradient(loss_value, original_model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, original_model.trainable_weights))\n","\n","    if step % batch_size == 0:\n","        print(\n","            \"Training loss (for one batch) at step %d: %.4f\"\n","            % (step, float(loss_value))\n","        )\n","        print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n","\n","\n","  for x_batch_val, y_batch_val in test_dataset:\n","      val_logits = original_model(x_batch_val, training=False)\n","      val_acc_metric.update_state(y_batch_val, val_logits)\n","      val_loss = val_loss_metric(y_batch_val, val_logits)\n","\n","  val_acc = val_acc_metric.result()\n","  val_acc_metric.reset_state()\n","  print(\"Validation acc: %.4f\" % (float(val_acc),))\n","  print(\"Validation loss: %.4f\" % (float(val_loss),))\n","\n","  if early_stopping:\n","    # Early stopping\n","    if float(val_loss) < best_loss:\n","        best_loss = float(val_loss)\n","        best_model_weights = copy.deepcopy(original_model.get_weights())  # Deep copy here\n","        patience = 20  # Reset patience counter\n","        print(f\"Early Stopping Restart\")\n","    else:\n","        patience -= 1\n","        print(f\"Early Stopping Patience {patience}\")\n","        if patience == 0:\n","            break\n","\n","## Sample Validation Results\n","# Epoch 49 => Validation acc: 0.7532\n","# Epoch 99 => Validation acc: 0.7532\n","# Epoch 49 => Validation acc: 0.7662\n","\n","## Early Stopping => Epoch 41: # Validation acc: 0.7662  # Validation loss: 0.5262\n","\n","model_backup = copy.deepcopy(original_model)\n","if early_stopping:\n","  original_model.set_weights(best_model_weights)\n","  print(\"Best Loss:\", best_loss)"],"metadata":{"id":"i8DDWafYWjfg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SHAP Value for Normal Learning"],"metadata":{"id":"CXetnDKVNzxC"}},{"cell_type":"code","source":["import shap\n","shap.initjs()\n","\n","# Calculate SHAP values\n","## KernelExplainer;\n","explainer = shap.DeepExplainer(original_model, np.array(X_test))\n","shap_values = explainer.shap_values(np.array(X_test))\n","# # Summarize the effects of features\n","shap.summary_plot(shap_values[:,:,-1], X_test)"],"metadata":{"id":"s10zKZZSO0Zd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shap.summary_plot(shap_values[:,:,-1], features=X_test, class_names=y_test.unique(), plot_type='bar')"],"metadata":{"id":"mwFuXzm5bmRX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## The importance values are ordered based on the feature names.\n","## Meaning: 'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'\n","importances = []\n","for i in range(shap_values.shape[1]):\n","    importances.append(np.mean(np.abs(shap_values[:, i])))\n","importances"],"metadata":{"id":"_E0sS4Y8eHkP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Fairness"],"metadata":{"id":"Nsg78lD-eUak"}},{"cell_type":"code","source":["X_test.columns"],"metadata":{"id":"ZaSSrzKxeUa5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = []\n","true_labels = []\n","ages = []\n","\n","## The age is our protected group.\n","## Hence, as the fairness metrics are used for binary classification,\n","## we map the age values using the average age recorded from the dataset\n","def age_map(i):\n","    return 0 if i < avg_age else 1\n","\n","for x_batch_val, y_batch_val in test_dataset:\n","  pred = constraint_model.predict(x_batch_val)\n","  predictions.append(tf.argmax(pred, axis=1).numpy())\n","  true_labels.append(y_batch_val.numpy())\n","\n","  map_age = np.vectorize(age_map)\n","  ages.append(map_age(x_batch_val[:,-1].numpy()))"],"metadata":{"id":"aR7mnT2peUa5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = []\n","y_true = []\n","feature_ages = []\n","\n","for age in ages:\n","    feature_ages.extend(age)\n","\n","for pred in predictions:\n","  y_pred.extend(pred)\n","\n","for label in true_labels:\n","  y_true.extend(label)\n","\n","y_pred = np.array(y_pred)\n","y_true = np.array(y_true)\n","feature_ages = np.array(feature_ages)\n","\n","y_pred.shape, y_true.shape, feature_ages.shape"],"metadata":{"id":"OgnEioPxeUa6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from fairlearn.metrics import demographic_parity_difference, demographic_parity_ratio\n","\n","img_preds = y_pred\n","img_true = y_true\n","\n","print(\"Demographic Parity Difference =  \", demographic_parity_difference(img_true, img_preds, sensitive_features=feature_ages))\n","print(\"Demographic Parity Ratio = \", demographic_parity_ratio(img_true, img_preds, sensitive_features=feature_ages))\n"],"metadata":{"id":"gfEZBsiWeUa6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from fairlearn.metrics import equalized_odds_difference, equalized_odds_ratio\n","print(\"Equality Odds Difference =  \", equalized_odds_difference(img_true, img_preds, sensitive_features=feature_ages))\n","print(\"Equality Odds Ratio = \", equalized_odds_ratio(img_true, img_preds, sensitive_features=feature_ages))\n"],"metadata":{"id":"kowHdgWAeUa7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### AUC and SPD"],"metadata":{"id":"h09MJoiYeUa7"}},{"cell_type":"code","source":["from sklearn import metrics\n","from aif360.sklearn.metrics import statistical_parity_difference\n","\n","AUC = metrics.roc_auc_score(y_test, y_pred)\n","print(\"AUC = \", AUC)\n","\n","SPD = statistical_parity_difference(pd.DataFrame(y_true), y_pred)\n","print(\"SPD = \", SPD)"],"metadata":{"id":"RjKwDh-JeUa7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Partial Dependence Plots (PDPs)"],"metadata":{"id":"l9SLdML4duXo"}},{"cell_type":"markdown","source":["The PDP plots are another widely mentioned technique for explainability, while produce insights into the partial dependence of different features based on their values.\n","\n","We haven't used this in reporting the evaluation results, though."],"metadata":{"id":"IeIgJP4tAfKy"}},{"cell_type":"code","source":["!pip install scikeras\n","!pip install scikit-learn==1.2.2"],"metadata":{"id":"VrIA_t3ihgZV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_features = list(X_test.columns)"],"metadata":{"id":"dkQXqIxVjS57"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["original_model.dummy_ = \"dummy\"\n","from sklearn.utils import validation\n","validation.check_is_fitted(estimator=original_model)"],"metadata":{"id":"kggrpCvXm8hR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from scikeras.wrappers import KerasClassifier\n","from sklearn.inspection import PartialDependenceDisplay"],"metadata":{"id":"vw9kQnWTnIdr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kr_original = KerasClassifier(build_fn=original_model, loss=loss_fn, optimizer=optimizer)\n","kr_original.fit(X_train, y_train, epochs=1)"],"metadata":{"id":"yxFOOUk5nz6P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr_original,\n","                                        X_test,\n","                                        features = ['Insulin'],\n","                                        feature_names = X_features,\n","                                        ax = ax);"],"metadata":{"id":"CnciqDJviJ-T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr_original,\n","                                        X_test,\n","                                        features = ['Glucose'],\n","                                        feature_names = X_features,\n","                                        ax = ax)"],"metadata":{"id":"1ByDV5_Fieuk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr_original,\n","                                        X_test,\n","                                        features = ['Age'],\n","                                        feature_names = X_features,\n","                                        ax = ax)"],"metadata":{"id":"2q5rnJObp_Xy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr_original,\n","                                        X_test,\n","                                        features = ['Pregnancies'],\n","                                        feature_names = X_features,\n","                                        ax = ax)"],"metadata":{"id":"ULNnnp66oK-J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Augmented Learning"],"metadata":{"id":"Z1iuHmqoeCfC"}},{"cell_type":"markdown","source":["### Knowledge Definition"],"metadata":{"id":"YVZkGJk8tLaC"}},{"cell_type":"code","source":["list(data['Pregnancies']).index(5), data_pd['Pregnancies'][list(data['Pregnancies']).index(5)]"],"metadata":{"id":"QmOpab_v9nTl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Constraints\n","## Original Values => not standardized using Scikit-Learn\n","# Pregnancies = {'P':[(0, 5, 0.2572178477690289)], 'N':[(0, 5, 0.7427821522309711)]}\n","# Insulin = {'P':[(200, None, 0.5411764705882353)] , 'N':[(0, 200, 0.7278688524590164)]}\n","# Glucose = {'P':[(170, None, 0.8405797101449275)], 'N':[(50, 75, 1.0), (30, 100, 0.9270833333333334)]}\n","# DPF = {'P':[], 'N':[(0, 0.25, 0.7463414634146341)]}\n","# BMI = {'P':[(50, 60, 0.7142857142857143)], 'N':[(0, 20, 1.0)]}\n","# BldPrsr = {'P':[(100, None, 0.6153846153846154)], 'N':[]}\n","# SkinTh = {'P':[(60, None, 1.0)], 'N':[(20, 40, 0.6310975609756098)]}\n","\n","## Scaled Values => After normalization and standardization using scikit-learn\n","Pregnancies = {'P':[(-1.141, 0.343, 0.257)], 'N':[(-1.141, 0.343, 0.743)]}\n","Insulin = {'P':[] , 'N':[(0, 1.0436, 0.7278)]}\n","Glucose = {'P':[(1.5368, np.inf, 0.8406)], 'N':[(-2.0310, -1.4363, 1.0), (-2.4066, -0.6539, 0.9271)]}\n","DPF = {'P':[], 'N':[(0, -0.6761, 0.7463)]}\n","BMI = {'P':[(2.2854, 3.4785, 0.7143)], 'N':[(0, -1.522, 1.0)]}\n","BldPrsr = {'P':[(1.5971, np.inf, 0.6154)], 'N':[]}\n","SkinTh = {'P':[(2.475, np.inf, 1.0)], 'N':[(-0.0336, 1.221, 0.6311)]}\n","\n","constraints = {'Pregnancies':Pregnancies, 'Insulin':Insulin, 'Glucose':Glucose,\n","               'DiabetesPedigreeFunction':DPF, 'BMI':BMI,\n","               'BloodPressure':BldPrsr, 'SkinThickness':SkinTh}"],"metadata":{"id":"Be4Vm0LktPJD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.columns"],"metadata":{"id":"U6un8iQ109KL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## You can either select the features individually or a combination of them using the All Constraints version.\n","## In case only one or a custom number of constraints are required, you can comment the others in code.\n","\n","def constraint_evaluator(outputs, features, constraints=constraints):\n","  preg = 0\n","  glucose = 0\n","  insulin = 0\n","  bmi = 0\n","  blp = 0\n","  dpf = 0\n","  skin = 0\n","\n","  ## Pregnancies => 0\n","  preg_bound = 1*(np.less_equal(constraints['Pregnancies']['P'][0][0], features[:,0])*np.less_equal(features[:,0],constraints['Pregnancies']['P'][0][1]))\n","  preg = preg_bound*((1-outputs)*constraints['Pregnancies']['P'][0][2] + (outputs)*constraints['Pregnancies']['N'][0][2])\n","\n","  # ## Glucose => 1\n","  glocuse_bound_p = 1*(np.less_equal(constraints['Glucose']['P'][0][0],features[:,1])*np.less_equal(features[:,1],constraints['Glucose']['P'][0][1]))\n","  glocuse_bound_n1 = 1*(np.less_equal(constraints['Glucose']['N'][0][0],features[:,1])*np.less_equal(features[:,1],constraints['Glucose']['N'][0][1]))\n","  glocuse_bound_n2 = 1*(np.less_equal(constraints['Glucose']['N'][1][0],features[:,1])*np.less_equal(features[:,1],constraints['Glucose']['N'][1][1]))\n","\n","  glucose_p = glocuse_bound_p*(1-outputs)*(constraints['Glucose']['P'][0][2])\n","  glucose_n = glocuse_bound_n1*outputs*(constraints['Glucose']['N'][0][2]) + glocuse_bound_n2*outputs*(constraints['Glucose']['N'][1][2])\n","  glucose = glucose_p+glucose_n\n","\n","  # BloodPressure => 2\n","  blp_bound = 1*(np.less_equal(constraints['BloodPressure']['P'][0][0], features[:,2])*np.less_equal(features[:,2],constraints['BloodPressure']['P'][0][1]))\n","  blp = blp_bound*((1-outputs)*constraints['BloodPressure']['P'][0][2])\n","\n","  # SkinThickness => 3\n","  skin_bound_p = 1*(np.less_equal(constraints['SkinThickness']['P'][0][0], features[:,3])*np.less_equal(features[:,3],constraints['SkinThickness']['P'][0][1]))\n","  skin_bound_n = 1*(np.less_equal(constraints['SkinThickness']['N'][0][0], features[:,3])*np.less_equal(features[:,3],constraints['SkinThickness']['N'][0][1]))\n","  skin = skin_bound_p*(1-outputs)*constraints['SkinThickness']['P'][0][2] + skin_bound_n *(outputs)*constraints['SkinThickness']['N'][0][2]\n","\n","  # Insuline => 4\n","  insulin_bound_n = 1*(np.less_equal(constraints['Insulin']['N'][0][0], features[:,4])*np.less_equal(features[:,4], constraints['Insulin']['N'][0][1]))\n","  insulin = insulin_bound_n*((outputs)*(constraints['Insulin']['N'][0][2]) + (1-outputs)*(1-constraints['Insulin']['N'][0][2]))\n","\n","  # BMI => 5\n","  BMI_bound_p = 1*(np.less_equal(constraints['BMI']['P'][0][0], features[:,5])*np.less_equal(features[:,5],constraints['BMI']['P'][0][1]))\n","  BMI_bound_n = 1*(np.less_equal(constraints['BMI']['N'][0][0], features[:,5])*np.less_equal(features[:,5],constraints['BMI']['N'][0][1]))\n","  bmi = BMI_bound_p*(1-outputs)*constraints['BMI']['P'][0][2] + BMI_bound_n *(outputs)*constraints['BMI']['N'][0][2]\n","\n","  ## DiabetesPedigreeFunction => 6\n","  DPF_bound = 1*(np.less_equal(constraints['DiabetesPedigreeFunction']['N'][0][0], features[:,5])*np.less_equal(features[:,5],constraints['DiabetesPedigreeFunction']['N'][0][1]))\n","  dpf = DPF_bound*((outputs)*constraints['DiabetesPedigreeFunction']['N'][0][2])\n","\n","\n","  return sum([preg, insulin, glucose, bmi, blp, dpf, skin])"],"metadata":{"id":"NtUtiNBm6UcL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training Loop"],"metadata":{"id":"U7_x1y5JB6sJ"}},{"cell_type":"code","source":["cons_coefficient = 1\n","\n","# Defining the Diabetes model\n","constraint_model = Sequential([\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(64, activation='relu'),\n","    Dense(32, activation='relu'),\n","    Dropout(0.5),\n","    Dense(2, activation='softmax')\n","])\n","\n","loss_fn = keras.losses.SparseCategoricalCrossentropy()\n","def custom_loss_function(logits, x_batch_train, y_batch_train):\n","   outputs = np.argmax(logits, axis=1)\n","   const_loss = np.mean(constraint_evaluator(outputs, x_batch_train))\n","   loss_value = loss_fn(y_batch_train, logits) + cons_coefficient*const_loss\n","   return loss_value\n","\n","optimizer = Adam()\n","n_epochs = 100\n","\n","## EarlyStopping\n","best_loss = float('inf')\n","best_model_weights = None\n","patience = 20\n","val_loss_metric = keras.losses.SparseCategoricalCrossentropy()\n","early_stopping = True\n","###\n","\n","\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","for epoch in range(n_epochs):\n","  print(\"\\nEpoch %d\" % (epoch,))\n","  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","    with tf.GradientTape() as tape:\n","        logits = constraint_model(x_batch_train, training=True)  # Logits for this minibatch\n","        # loss_value = custom_loss_function(logits, x_batch_train, y_batch_train)\n","        outputs = np.argmax(logits, axis=1)\n","        const_loss = np.mean(constraint_evaluator(outputs, x_batch_train))\n","        loss_value = loss_fn(y_batch_train, logits) + cons_coefficient*const_loss\n","\n","    grads = tape.gradient(loss_value, constraint_model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, constraint_model.trainable_weights))\n","\n","    if step % batch_size == 0:\n","        print(\n","            \"Training loss (for one batch) at step %d: %.4f\"\n","            % (step, float(loss_value))\n","        )\n","        print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n","\n","\n","  for x_batch_val, y_batch_val in test_dataset:\n","      val_logits = constraint_model(x_batch_val, training=False)\n","      val_acc_metric.update_state(y_batch_val, val_logits)\n","      val_loss = val_loss_metric(y_batch_val, val_logits)\n","\n","  val_acc = val_acc_metric.result()\n","  val_acc_metric.reset_state()\n","  print(\"Validation acc: %.4f\" % (float(val_acc),))\n","  print(\"Validation loss: %.4f\" % (float(val_loss),))\n","\n","  if early_stopping:\n","    # Early stopping\n","    if float(val_loss) < best_loss:\n","        best_loss = float(val_loss)\n","        best_model_weights = copy.deepcopy(constraint_model.get_weights())  # Deep copy here\n","        patience = 20  # Reset patience counter\n","        print(f\"Early Stopping Restart\")\n","    else:\n","        patience -= 1\n","        print(f\"Early Stopping Patience {patience}\")\n","        if patience == 0:\n","            break\n","\n","model_backup = copy.deepcopy(constraint_model)\n","if early_stopping:\n","  constraint_model.set_weights(best_model_weights)\n","  print(\"Best Loss:\", best_loss)\n"],"metadata":{"id":"LRxGJ7CyZGHd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SHAP Value"],"metadata":{"id":"aNTXV2gRUCDy"}},{"cell_type":"code","source":["import shap\n","shap.initjs()\n","\n","# Calculate SHAP values\n","## KernelExplainer;\n","explainer = shap.DeepExplainer(constraint_model, np.array(X_test))\n","shap_values = explainer.shap_values(np.array(X_test))\n","## Summarize the effects of features\n","shap.summary_plot(shap_values[:,:,-1], X_test)"],"metadata":{"id":"EaL21Kv_gFbk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shap.summary_plot(shap_values[:,:,-1], features=X_test, class_names=y_test.unique(), plot_type='bar')"],"metadata":{"id":"LGcNjOeegFb-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["importances = []\n","for i in range(shap_values.shape[1]):\n","    importances.append(np.mean(np.abs(shap_values[:, i])))\n","importances"],"metadata":{"id":"Pi8UKVh-gFb_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Partial Dependence Plots (PDPs)"],"metadata":{"id":"uoRGYqk_o_D3"}},{"cell_type":"code","source":["X_features = list(X_test.columns)"],"metadata":{"id":"3kxx-867o_D5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["constraint_model.dummy_ = \"dummy\"\n","from sklearn.utils import validation\n","validation.check_is_fitted(estimator=constraint_model)"],"metadata":{"id":"kQ0_l0E9o_D5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.inspection import PartialDependenceDisplay\n","from scikeras.wrappers import KerasClassifier"],"metadata":{"id":"GD2C2Vl8o075"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kr = KerasClassifier(build_fn=constraint_model, loss=loss_fn, optimizer=optimizer)\n","kr.fit(X_train, y_train, epochs=1)"],"metadata":{"id":"vK_tNnmio_D6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.columns"],"metadata":{"id":"8tK2hL8_4UlR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['Pregnancies'],\n","                                        feature_names = X_features,\n","                                        ax = ax);"],"metadata":{"id":"wWesNV5G4JwD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['Glucose'],\n","                                        feature_names = X_features,\n","                                        ax = ax);"],"metadata":{"id":"tUJrqjPco_D7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['BloodPressure'],\n","                                        feature_names = X_features,\n","                                        ax = ax)"],"metadata":{"id":"jIaAtFn3p3Sr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['SkinThickness'],\n","                                        feature_names = X_features,\n","                                        ax = ax)"],"metadata":{"id":"DA3SgLNVo_D8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['Insulin'],\n","                                        feature_names = X_features,\n","                                        ax = ax)"],"metadata":{"id":"UMn4rNBXxLbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['BMI'],\n","                                        feature_names = X_features,\n","                                        ax = ax)"],"metadata":{"id":"vcB5-kbV4TmI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['DiabetesPedigreeFunction'],\n","                                        feature_names = X_features,\n","                                        ax = ax)"],"metadata":{"id":"3QfMICLG4iNC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Enhanced Augmented Learning"],"metadata":{"id":"c0UNpGhvA-wC"}},{"cell_type":"markdown","source":["### Knowledge Definition"],"metadata":{"id":"vePZz3ftCL7W"}},{"cell_type":"code","source":["list(data['DiabetesPedigreeFunction'])"],"metadata":{"id":"X3kLB4IwpsPt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 0.17\n","list(data['DiabetesPedigreeFunction']).index(i), data_pd['DiabetesPedigreeFunction'][list(data['DiabetesPedigreeFunction']).index(i)]"],"metadata":{"id":"7RSm1w7LCL7W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Constraints\n","## Original Values\n","# Pregnancies = {'P':[(0, 5, 0.2572178477690289)], 'N':[(0, 5, 0.7427821522309711)]}\n","# Insulin = {'P':[(200, None, 0.5411764705882353)] , 'N':[(0, 200, 0.7278688524590164)]}\n","# Glucose = {'P':[(170, None, 0.8405797101449275)], 'N':[(50, 75, 1.0), (30, 100, 0.9270833333333334)]}\n","# DPF = {'P':[], 'N':[(0, 0.25, 0.7463414634146341)]}\n","# BMI = {'P':[(50, 60, 0.7142857142857143)], 'N':[(0, 20, 1.0)]}\n","# BldPrsr = {'P':[(100, None, 0.6153846153846154)], 'N':[]}\n","# SkinTh = {'P':[(60, None, 1.0)], 'N':[(20, 40, 0.6310975609756098)]}\n","\n","## Scaled Values\n","Pregnancies = {'P':[(-1.141, 0.343, 0.257)], 'N':[(-1.141, 0.343, 0.743)]}\n","Insulin = {'P':[] , 'N':[(0, 1.0436, 0.7278)]}\n","Glucose = {'P':[(1.5368, np.inf, 0.8406)], 'N':[(-2.0310, -1.4363, 1.0), (-2.4066, -0.6539, 0.9271)]}\n","DPF = {'P':[], 'N':[(-1, -0.6761, 0.7463)]}\n","BMI = {'P':[(2.2854, 3.4785, 0.7143)], 'N':[(-2, -1.522, 1.0)]}\n","BldPrsr = {'P':[(1.5971, np.inf, 0.6154)], 'N':[]}\n","SkinTh = {'P':[(2.475, np.inf, 1.0)], 'N':[(-0.0336, 1.221, 0.6311)]}\n","\n","constraints = {'Pregnancies':Pregnancies, 'Insulin':Insulin, 'Glucose':Glucose,\n","               'DiabetesPedigreeFunction':DPF, 'BMI':BMI,\n","               'BloodPressure':BldPrsr, 'SkinThickness':SkinTh}"],"metadata":{"id":"p3wu3WVUCL7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.columns"],"metadata":{"id":"0tRQ3Cr2CL7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def constraint_evaluator(outputs, features, weights, meu, constraints=constraints):\n","\n","  consts_outs = {key: 0 for key in constraints.keys()}\n","\n","  # ## Pregnancies => 0\n","  preg_bound = 1*(np.less_equal(constraints['Pregnancies']['P'][0][0], features[:,0])*np.less_equal(features[:,0],constraints['Pregnancies']['P'][0][1]))\n","  preg = preg_bound*((1-outputs)*constraints['Pregnancies']['P'][0][2] + (outputs)*constraints['Pregnancies']['N'][0][2])\n","  consts_outs['Pregnancies'] = preg\n","\n","  # ## Glucose => 1\n","  glocuse_bound_p = 1*(np.less_equal(constraints['Glucose']['P'][0][0],features[:,1])*np.less_equal(features[:,1],constraints['Glucose']['P'][0][1]))\n","  glocuse_bound_n1 = 1*(np.less_equal(constraints['Glucose']['N'][0][0],features[:,1])*np.less_equal(features[:,1],constraints['Glucose']['N'][0][1]))\n","  glocuse_bound_n2 = 1*(np.less_equal(constraints['Glucose']['N'][1][0],features[:,1])*np.less_equal(features[:,1],constraints['Glucose']['N'][1][1]))\n","\n","  glucose_p = glocuse_bound_p*(1-outputs)*(constraints['Glucose']['P'][0][2])\n","  glucose_n = glocuse_bound_n1*outputs*(constraints['Glucose']['N'][0][2]) + glocuse_bound_n2*outputs*(constraints['Glucose']['N'][1][2])\n","  glucose = glucose_p+glucose_n\n","  consts_outs['Glucose'] = glucose\n","\n","  # BloodPressure => 2\n","  blp_bound = 1*(np.less_equal(constraints['BloodPressure']['P'][0][0], features[:,2])*np.less_equal(features[:,2],constraints['BloodPressure']['P'][0][1]))\n","  blp = blp_bound*((1-outputs)*constraints['BloodPressure']['P'][0][2])\n","  consts_outs['BloodPressure'] = blp\n","\n","\n","  # SkinThickness => 3\n","  skin_bound_p = 1*(np.less_equal(constraints['SkinThickness']['P'][0][0], features[:,3])*np.less_equal(features[:,3],constraints['SkinThickness']['P'][0][1]))\n","  skin_bound_n = 1*(np.less_equal(constraints['SkinThickness']['N'][0][0], features[:,3])*np.less_equal(features[:,3],constraints['SkinThickness']['N'][0][1]))\n","  skin = skin_bound_p*(1-outputs)*constraints['SkinThickness']['P'][0][2] + skin_bound_n *(outputs)*constraints['SkinThickness']['N'][0][2]\n","  consts_outs['SkinThickness'] = skin\n","\n","  # Insuline => 4\n","  insulin_bound_n = 1*(np.less_equal(constraints['Insulin']['N'][0][0], features[:,4])*np.less_equal(features[:,4], constraints['Insulin']['N'][0][1]))\n","  insulin = insulin_bound_n*((outputs)*(constraints['Insulin']['N'][0][2]) + (1-outputs)*(1-constraints['Insulin']['N'][0][2]))\n","  consts_outs['Insulin'] = insulin\n","\n","\n","  ## BMI => 5\n","  BMI_bound_p = 1*(np.less_equal(constraints['BMI']['P'][0][0], features[:,5])*np.less_equal(features[:,5],constraints['BMI']['P'][0][1]))\n","  BMI_bound_n = 1*(np.less_equal(constraints['BMI']['N'][0][0], features[:,5])*np.less_equal(features[:,5],constraints['BMI']['N'][0][1]))\n","  bmi = BMI_bound_p*(1-outputs)*constraints['BMI']['P'][0][2] + BMI_bound_n *(outputs)*constraints['BMI']['N'][0][2]\n","  consts_outs['BMI'] = bmi\n","\n","\n","  # DiabetesPedigreeFunction => 6\n","  DPF_bound = 1*(np.less_equal(constraints['DiabetesPedigreeFunction']['N'][0][0], features[:,5])*np.less_equal(features[:,5],constraints['DiabetesPedigreeFunction']['N'][0][1]))\n","  dpf = DPF_bound*((outputs)*constraints['DiabetesPedigreeFunction']['N'][0][2])\n","  consts_outs['DiabetesPedigreeFunction'] = dpf\n","\n","  final_output = {key: 0 for key in constraints.keys()}\n","  for key in constraints.keys():\n","    final_output[key] = weights[key]*np.mean(consts_outs[key]) + (meu/2)*(max(0, np.mean(consts_outs[key]))**2)\n","\n","  return final_output"],"metadata":{"id":"Y7TwbIcACL7X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Training Loop"],"metadata":{"id":"75iGjfcKCOvf"}},{"cell_type":"code","source":["cons_landas = {key: 0 for key in constraints.keys()}\n","meu = 0.5\n","C = 0.5\n","delta = 0.01\n","threshold = 0.5\n","\n","# Define the Diabetes model\n","constraint_model = Sequential([\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(64, activation='relu'),\n","    Dense(32, activation='relu'),\n","    Dropout(0.5),\n","    Dense(2, activation='softmax')\n","])\n","\n","loss_fn = keras.losses.SparseCategoricalCrossentropy()\n","optimizer = Adam()\n","n_epochs = 100\n","\n","\n","## EarlyStopping\n","best_loss = float('inf')\n","best_model_weights = None\n","patience = 20\n","val_loss_metric = keras.losses.SparseCategoricalCrossentropy()\n","early_stopping = True\n","###\n","\n","\n","val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n","\n","for epoch in range(n_epochs):\n","  print(\"\\nEpoch %d\" % (epoch,))\n","  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","    with tf.GradientTape() as tape:\n","        logits = constraint_model(x_batch_train, training=True)  # Logits for this minibatch\n","        outputs = np.argmax(logits, axis=1)\n","\n","        theta_loss = 0\n","        for weight in constraint_model.get_weights():\n","          theta_loss += delta*tf.nn.l2_loss(weight)\n","\n","        const_output = constraint_evaluator(outputs, x_batch_train, cons_landas, meu)\n","        const_loss = sum(list(const_output.values()))\n","\n","        logit_loss = loss_fn(y_batch_train, logits)\n","        loss_value = logit_loss + theta_loss + const_loss\n","\n","    grads = tape.gradient(loss_value, constraint_model.trainable_weights)\n","    optimizer.apply_gradients(zip(grads, constraint_model.trainable_weights))\n","\n","    sum_consts = 0\n","    for key in cons_landas.keys():\n","      cons_landas[key] += meu*max(0, const_output[key])\n","      sum_consts += max(0, const_output[key])**2\n","    # print(\"Landa\", cons_landas)\n","\n","    if sum_consts > threshold:\n","      meu *= C\n","\n","    if step % batch_size == 0:\n","        print(\n","            \"Training loss, Consts, and Theta loss loss at step %d: %.4f, %.4f, %.4f\"\n","            % (step, float(loss_value), float(const_loss), float(theta_loss))\n","        )\n","        print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n","        print(\"Consts Landas:\", cons_landas)\n","\n","\n","  for x_batch_val, y_batch_val in test_dataset:\n","      val_logits = constraint_model(x_batch_val, training=False)\n","      val_acc_metric.update_state(y_batch_val, val_logits)\n","      val_loss = val_loss_metric(y_batch_val, val_logits)\n","\n","  val_acc = val_acc_metric.result()\n","  val_acc_metric.reset_state()\n","  print(\"Validation acc: %.4f\" % (float(val_acc),))\n","  print(\"Validation loss: %.4f\" % (float(val_loss),))\n","\n","  if early_stopping:\n","    # Early stopping\n","    if float(val_loss) < best_loss:\n","        best_loss = float(val_loss)\n","        best_model_weights = copy.deepcopy(constraint_model.get_weights())  # Deep copy here\n","        patience = 20  # Reset patience counter\n","        print(f\"Early Stopping Restart\")\n","    else:\n","        patience -= 1\n","        print(f\"Early Stopping Patience {patience}\")\n","        if patience == 0:\n","            break\n","\n","model_backup = copy.deepcopy(constraint_model)\n","if early_stopping:\n","  constraint_model.set_weights(best_model_weights)\n","  print(\"Best Loss:\", best_loss)\n",""],"metadata":{"id":"RvT2LcliCL7X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SHAP Value"],"metadata":{"id":"KoZY3PmVCL7Y"}},{"cell_type":"code","source":["import shap\n","shap.initjs()\n","\n","# Calculate SHAP values\n","## KernelExplainer;\n","explainer = shap.DeepExplainer(constraint_model, np.array(X_test))\n","shap_values = explainer.shap_values(np.array(X_test))\n","## Summarize the effects of features\n","shap.summary_plot(shap_values[:,:,-1], X_test)"],"metadata":{"id":"Sm0czwCsCL7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["shap.summary_plot(shap_values[:,:,-1], features=X_test, class_names=y_test.unique(), plot_type='bar')"],"metadata":{"id":"6TWt2ytqCL7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["importances = []\n","for i in range(shap_values.shape[1]):\n","    importances.append(np.mean(np.abs(shap_values[:, i])))\n","importances"],"metadata":{"id":"yvYx85owCL7Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Fairness"],"metadata":{"id":"hT5K1VmXS04o"}},{"cell_type":"code","source":["X_test.columns"],"metadata":{"id":"DX_0RIT8TYPU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = []\n","true_labels = []\n","ages = []\n","\n","def age_map(i):\n","    return 0 if i < avg_age else 1\n","\n","for x_batch_val, y_batch_val in test_dataset:\n","  pred = constraint_model.predict(x_batch_val)\n","  predictions.append(tf.argmax(pred, axis=1).numpy())\n","  true_labels.append(y_batch_val.numpy())\n","\n","  map_age = np.vectorize(age_map)\n","  ages.append(map_age(x_batch_val[:,-1].numpy()))"],"metadata":{"id":"rcd1lqVnyMi2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = []\n","y_true = []\n","feature_ages = []\n","\n","for age in ages:\n","    feature_ages.extend(age)\n","\n","for pred in predictions:\n","  y_pred.extend(pred)\n","\n","for label in true_labels:\n","  y_true.extend(label)\n","\n","y_pred = np.array(y_pred)\n","y_true = np.array(y_true)\n","feature_ages = np.array(feature_ages)\n","\n","y_pred.shape, y_true.shape, feature_ages.shape"],"metadata":{"id":"pynXrlDVyMjD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from fairlearn.metrics import demographic_parity_difference, demographic_parity_ratio\n","\n","img_preds = y_pred\n","img_true = y_true\n","\n","print(\"Demographic Parity Difference =  \", demographic_parity_difference(img_true, img_preds, sensitive_features=feature_ages))\n","print(\"Demographic Parity Ratio = \", demographic_parity_ratio(img_true, img_preds, sensitive_features=feature_ages))\n"],"metadata":{"id":"J6vjXZBBzjC7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from fairlearn.metrics import equalized_odds_difference, equalized_odds_ratio\n","print(\"Equality Odds Difference =  \", equalized_odds_difference(img_true, img_preds, sensitive_features=feature_ages))\n","print(\"Equality Odds Ratio = \", equalized_odds_ratio(img_true, img_preds, sensitive_features=feature_ages))\n"],"metadata":{"id":"ON5VemSEzjDU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### AUC and SPD"],"metadata":{"id":"yceouMyjVb1q"}},{"cell_type":"code","source":["from sklearn import metrics\n","from aif360.sklearn.metrics import statistical_parity_difference\n","\n","AUC = metrics.roc_auc_score(y_test, y_pred)\n","print(\"AUC = \", AUC)\n","\n","SPD = statistical_parity_difference(pd.DataFrame(y_true), y_pred)\n","print(\"SPD = \", SPD)"],"metadata":{"id":"DWiwQl9YVeYI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Partial Dependence Plots (PDPs)"],"metadata":{"id":"yWBIFLMiCL7Z"}},{"cell_type":"code","source":["X_features = list(X_test.columns)"],"metadata":{"id":"jcuXwnuhCL7Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["constraint_model.dummy_ = \"dummy\"\n","from sklearn.utils import validation\n","validation.check_is_fitted(estimator=constraint_model)"],"metadata":{"id":"5UG1Dq5CCL7Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.inspection import PartialDependenceDisplay\n","from scikeras.wrappers import KerasClassifier"],"metadata":{"id":"xIeaR_Y2CL7Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kr = KerasClassifier(build_fn=constraint_model, loss=loss_fn, optimizer=optimizer)\n","kr.fit(X_train, y_train, epochs=1)"],"metadata":{"id":"LDxKejMUCL7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.columns"],"metadata":{"id":"5a1eoGEVCL7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['Pregnancies'],\n","                                        feature_names = X_features,\n","                                        ax = ax);"],"metadata":{"id":"c71E_V88CL7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['Glucose'],\n","                                        feature_names = X_features,\n","                                        ax = ax);"],"metadata":{"id":"CjDMAPD5CL7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['BloodPressure'],\n","                                        feature_names = X_features,\n","                                        ax = ax)"],"metadata":{"id":"bIjNjqD5CL7b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['SkinThickness'],\n","                                        feature_names = X_features,\n","                                        ax = ax)"],"metadata":{"id":"hEhXuMdnCL7b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['Insulin'],\n","                                        feature_names = X_features,\n","                                        ax = ax)"],"metadata":{"id":"qPE_Hb1DCL7b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['BMI'],\n","                                        feature_names = X_features,\n","                                        ax = ax)"],"metadata":{"id":"YCxhNsKGCL7b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12, 6))\n","ax.set_title(\"Partial Dependency Plot\")\n","PartialDependenceDisplay.from_estimator(kr,\n","                                        X_test,\n","                                        features = ['DiabetesPedigreeFunction'],\n","                                        feature_names = X_features,\n","                                        ax = ax)"],"metadata":{"id":"YZm0BDxpCL7b"},"execution_count":null,"outputs":[]}]}